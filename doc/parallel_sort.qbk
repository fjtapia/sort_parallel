[library Boost.Parallel_Sort
  [quickbook 1.6]
  [id parallel_sort]
  [copyright 2017 Francisco Tapia]
  [authors [Tapia, Francisco]]
  [dirname parallel_sort]
  [license Distributed under the
    [@http://boost.org/LICENSE_1_0.txt Boost Software License,  Version 1.0].
  ]
]

[/ Some composite templates]
[template super[x]'''<superscript>'''[x]'''</superscript>''']
[template sub[x]'''<subscript>'''[x]'''</subscript>''']
[template floor[x]'''&#x230A;'''[x]'''&#x230B;''']
[template floorlr[x][lfloor][x][rfloor]]
[template ceil[x] '''&#x2308;'''[x]'''&#x2309;''']

[/ Required for autoindexing]
[import ../../../tools/auto_index/include/auto_index_helpers.qbk]
[/ Must be first included file!]



[section 1.- Introduction]

[section 1.1.- Description]

This library provides both *stable and unstable* sorting algorithms, in *single threaded and parallel* versions.

These algorithms *do not use any other library or utility*. Compiling this library requires a *C++11 compliant compiler*.

The algorithms use a *comparison object*, in the same way as the standard library sort 
algorithms. If you don't define it, the comparison object defaults to std::less, which uses 
the < operator internally for comparisons.

The algorithms are *exception safe*,  meaning that, the exceptions generated by the algorithms 
guarantee the integrity of the objects to sort, but not their relative order. If the exception
is generated inside the objects (in the move or in the copy constructor.. ) the results can be 
unpredictable.

This library is *include only*. There is no need to link with any external static or dynamic library.
This doesn't depend on any other boost files, variables or libraries or any other external libraries. 
To use this library, just include the files in the boost/sort/parallel folder.
	 
This table provides you a brief description of the sort algorithms in the library.

[table AlgorithmDescription
[[Algorithm] 			[Parallel]	[Stable][Additional Memory] 		[Best, average, and worst case]]
[[sort]      			[No]      	[No]    [Log N]			  			[NlogN, NlogN , NlogN]] 
[[stable sort] 			[No] 		[Yes]	[N / 2] 					[NlogN, NlogN , NlogN]]
[[parallel_sort] 		[Yes] 		[No]	[block_size * num_threads]	[NlogN, NlogN , NlogN]]
[[parallel_stable_sort]	[Yes]		[Yes]	[N / 2]						[NlogN, NlogN , NlogN]]
[[sample_sort]			[Yes]		[Yes]	[N]							[NlogN, NlogN , NlogN]]
]
The block_size is an internal parameter of the algorithm, which in order to achieve the 
highest speed, change according the size of the objects to sort according the next table. 
The strings use a block_size of 128.

[table BlockSize
[[object size (bytes)]				[1 - 15][16 - 31][32 - 63][64 - 127][128 - 255][256 - 511][512 -]]
[[block_size (number of elements)]	[4096]	[2048]		[1024][768][512][256][128]]
]
[endsect] [/section 1.1.- Description]



[section 1.2.- Present Perspective]

There are two primary categories of parallelization in sorting algorithms.
	 
[*SUBDIVISION ALGORITHMS]

[:Filter the data and generate two or more parts. Each part obtained is 
filtered and divided by other threads, until the size of the data to
sort is smaller than a predefined size, then it is sorted by a single
thread. The algorithm most frequently used in the filter and sorting
is quick sort

These algorithms are fast with a small number of threads, but are inefficient 
with a great number of HW (hardware) threads. Examples of this category are 
# Intel Threading Building Blocks (TBB)
# Microsoft PPL Parallel Sort.
]

[*MERGING ALGORITHMS]

[:Divide the data in parts, and each part is sorted by a thread. When
the parts are sorted, they are merged to obtain the final results. The
problem of these algorithms is they need additional memory for the
merge, usually the same size as the data.

With a small number of threads, these algorithms have similar speed to
than the subdivision algorithms, but with span style=font-weight: bold;many
threads they are much faster/span . Examples of this category are
# GCC Parallel Sort (based on OpenMP)
# Microsoft PPL Parallel Buffered Sort
]
[endsect] [/section 1.2.- Present Perspective]
[br]


[section 1.3.- New Parallel Sort Algorithm]

This generates an undesirable duality. With a small number of threads the optimal algorithm is not the optimal for a big number of threads. For this reason, the SW designed for a small machine is inadequate for a big machine and vice versa. But the main problem for the merging algorithms is the additional memory used, usually of the same size as the data.

This version have as a *new parallel_sort algorithm* (internally named Block Indirect), created for processors connected with shared memory.
It is a hybrid algorithm. With small number of threads, it is a subdivision algorithm, but with many threads is a merging algorithms, which need a small  auxiliary memory ( block_size * number of threads).


The block_size is an internal parameter of the algorithm, which in order to achieve the 
highest speed, change according the size of the objects to sort according the next table. 
The strings use a block_size of 128.

[table BlockSize
[[object size (bytes)]				[1 - 15][16 - 31][32 - 63][64 - 127][128 - 255][256 - 511][512 -]]
[[block_size (number of elements)]	[4096]	[2048]		[1024][768][512][256][128]]
]

This algorithm eliminates the duality. You compile your program using the new algorithms. When your program runs on a machine with a small number of threads the algorithm internally uses a subdivision algorithm and  has similar performance to  TBB, and when run on a machine with many threads, internally uses the new algorithm and has the performance of GCC Parallel Sort, with the additional advantage of reduced memory consumption.

The algorithm uses an auxiliary memory of block_size elements for each thread. The worst case for the algorithm is when there are very big elements and many threads. With big elements (512 bytes), and 12 threads, The memory measured was:

[table MemoryUsed
[[Algorithm][Memory used in MB]]
[[GCC Parallel Sort (OpenMP)][1565 MB]]
[[Threading Building Blocks (TBB)][783 MB]]
[[Block Indirect Sort][812 MB]]
]

This new parallel_sort algorithm had been created and implemented specifically for this library by the author.

If you are interested in a brief description of the algorithm, you can find in the next link [@../../doc/papers/block_indirect_sort_brief_en.pdf Block Indirect Sort Brief]. 

If you are interested in a detailed description of the algorithm, you can find in the next link [@../../doc/papers/block_indirect_sort_en.pdf Block Indirect Sort].
.

If you want run the benchmarks in your machine, all the code, instructions and procedures are in  ([@https://github.com/fjtapia/sort_parallel_benchmark Sort Parallel Benchmarks])

[endsect] [/section 1.3.- New Parallel Sort Algorithm]
[br]

[section 1.4.- Thread specification in the parallel algorithms]

The parallel algorithms have a parameter indicating the number of thread to use in the sorting process, which always is the last value in the call. The default value (if left unspecified) is the number of HW threads of the machine where the program is running.

The parallel algorithms have 4 invocation formats:

    algorithm ( first iterator, last iterator, comparison object, number of threads )
    algorithm ( first iterator, last iterator, comparison object )
    algorithm ( first iterator, last iterator, number of threads )
    algorithm ( first iterator, last iterator )

If no comparison object is specified, the default class ( std::less<value_t> ) is used.

If the number of threads is unspecified, the number of HW threads on the machine where the the program is running is used

[endsect] [/section 1.4.- Thread specification in the parallel algorithms]
[br]

[section 1.5.- Programing]
 
You only need to include the file boost/sort/parallel/sort.hpp if you wish to use this


	#include <boost/sort/parallel/sort.hpp>
          

All the functions and definitions are in the namespace boost::sort::parallel
[endsect] [/section 1.5.- Programing]
[br]
[section 1.6.- Examples]

This example uses the single threaded sort and stable_sort.


	#include <iostream>
	#include <vector>#include <random>
	#include <boost/sort/parallel/sort.hpp>namespace bsp = boost::sort::parallel;
			  
	int main (void)
	{   //-------------- begin------------
		std::mt19937_64 my_rand(0);
		const uint32_t NMAX = 1000000;
		std::vector <uint64_t> A, B;

		for (uint32_t i = 0; i < NMAX; ++i)  A.push_back(my_rand());
		B = A;
		bsp::sort (A.begin(), A.end());
		bsp::stable_sort (B.begin(), B.end());

		for (uint32_t i = 0; i < NMAX; ++i)
		    if (A[i] != B[i])  std::cout<<"Error in the sorting process\n";
		return 0;
	};


This example uses parallel_sort and sample_sort.


	#include <iostream>
	#include <vector>
	#include <random>
	#include <boost/sort/parallel/sort.hpp>
	namespace bsp = boost::sort::parallel;

	int main( void )
	{   //-------------- begin------------
		std::mt19937_64 my_rand(0);
		const uint32_t NMAX = 1000000;    std::vector <uint64_t> A, B;
		
		for (uint32_t i = 0; i < NMAX; ++i) A.push_back (my_rand());
		B = A ;
		//------------------------------------------------------------------------
		// if the thread parameter is not specified, the number of thread used
		// is the number of HW threads of the machine where the program is running.
		// This number is calculate in each execution of the code
		//------------------------------------------------------------------------
		bsp::parallel_sort (A.begin(), A.end());
		bsp::sample_sort (B.begin(), B.end());

		for (uint32_t i = 0; i < NMAX; ++i)
		    if (A[i] != B[i]) std::cout<<"Error in the sorting process\n";
		return 0 ;
	}; 


This example uses parallel_sort and sample_sort and specifies the thread count.

	#include <iostream>
	#include <vector>
	#include <random>
	#include <boost/sort/parallel/sort.hpp>
	namespace bsp = boost::sort::parallel;int main (void)
	{   //-------------- begin------------
		std::mt19937_64 my_rand(0);
		const uint32_t NMAX = 1000000;
		    uint32_t number_threads = std::thread::hardware_concurrency();
		std::vector <uint64_t> A, B ;
		for (uint32_t i = 0; i < NMAX; ++i)  A.push_back (my_rand());
		B = A ;
		//------------------------------------------------------------------------
		// If the result of number_threads / 6 is smaller than 1, internally use 1 thread
		//------------------------------------------------------------------------
		bsp::parallel_sort (A.begin(), A.end(), number_threads / 6);
		//------------------------------------------------------------------------
		//  force to execute with 100 threads
		//------------------------------------------------------------------------
		bsp::sample_sort (B.begin(), B.end(), 100);

		for (uint32_t i = 0; i < NMAX ; ++i)
		    if (A[i] != B[i])  std::cout<<"Error in the sorting process\n";
		return 0 ;
	}; 
	
[endsect] [/section 1.6.- Examples]
[endsect] [/section 1.- Introduction]
[br]

[section 2.- Algorithms]

[section 2.1.- Single Thread ( sort, stable_sort)]
[h3 sort]

Sort is a implementation of the Introsort algorithm. Initially it uses quicksort, but when the numbers of division is greater than a number, it changes to the heapsort algorithm.

Heapsort is a O(NlogN) algorithm but slower than quick_sort. This is to prevent the worst case of QuickSort (N²).

[table sort
[[Algorithm] 			[Parallel]	[Stable][Additional Memory] 		[Best, average, and worst case]]
[[sort]      			[No]      	[No]    [Log N]			  			[NlogN, NlogN , NlogN]] 
]

	template <class iter_t, typename compare>
	void sort (iter_t first, iter_t last, compare comp = compare()) ;

[h3 stable_sort]
 
This is a new single threaded stable sort algorithm, internally named spin_sort, created and developed specifically for this library. This algorithm combines several ideas to improve on other stable sort algorithms.

In the benchmarks you can find a detailed description of the results in time and memory obtained. This algorithm uses an auxiliary memory of (N/2) elements.

[table stable_sort
[[Algorithm] 			[Parallel]	[Stable][Additional Memory] 		[Best, average, and worst case]]
[[stable sort] 			[No] 		[Yes]	[N / 2] 					[NlogN, NlogN , NlogN]]
]

	template <class iter_t,  typename compare>
	void stable_sort (iter_t first, iter_t last, compare comp = compare());

[endsect] [/section 2.1.- Single Thread ( sort, stable_sort)]

[section 2.2.- Parallel ( parallel_sort, parallel_stable_sort, sample_sort)]
[h3 parallel_sort]

This is the new algorithm  Block Indirect Sort. It's a hybrid algorithm, because with a small number of HW threads it uses a parallel version of introsort, and with a number of threads > 5 uses the new algorithm.  When the number of threads is 1, it uses introsort.

This algorithm combines the speed of GCC Parallel Sort with many cores, with the small memory consumption of Threading Building Blocks (TBB). This algorithm had been created and implemented by the author for this library.  The auxiliary memory needed is ( block_size * num of threads.) (See description in 1.3.- New Parallel Sort Algorithm )

[table parallel_sort
[[Algorithm] 			[Parallel]	[Stable][Additional Memory] 		[Best, average, and worst case]]
[[parallel_sort] 		[Yes] 		[No]	[block_size * num_threads]	[NlogN, NlogN , NlogN]]
]

	template <class iter_t>
	void parallel_sort (iter_t first, iter_t last);

	template <class iter_t, typename compare>
	void parallel_sort (iter_t first, iter_t last, compare comp);

	template <class iter_t>
	void parallel_sort (iter_t first, iter_t last, uint32_t num_thread);

	template <class iter_t, typename compare>
	void parallel_sort (iter_t first, iter_t last, compare comp, uint32_t num_thread);
 


[h3 parallel_stable_sort]

This is a parallel stable sort algorithm, built on top of the sample sort algorithm , bust using less auxiliary memory (N / 2 elements) in exchange for slowing it down about 10%.

[table parallel_stable_sort
[[Algorithm] 			[Parallel]	[Stable][Additional Memory] 		[Best, average, and worst case]]
[[parallel_stable_sort]	[Yes]		[Yes]	[N / 2]						[NlogN, NlogN , NlogN]]
]

	template <class iter_t>
	void parallel_stable_sort (iter_t first, iter_t last);

	template <class iter_t, typename compare>
	void parallel_stable_sort (iter_t first, iter_t last, compare comp);

	template <class iter_t>
	void parallel_stable_sort (iter_t first, iter_t last, uint32_t num_thread);

	template <class iter_t, typename compare>
	void parallel_stable_sort (iter_t first, iter_t last, compare comp, uint32_t num_thread);


[h3 sample_sort]
 
This is a parallel stable sort algorithm. It is faster than parallel_stable_sort but the auxiliary memory used is N elements.
You can see the details in the benchmark chapter

[table sample_sort
[[Algorithm] 			[Parallel]	[Stable][Additional Memory] 		[Best, average, and worst case]]
[[sample_sort]			[Yes]		[Yes]	[N]							[NlogN, NlogN , NlogN]]
]

	template <class iter_t>
	void sample_sort (iter_t first, iter_t last);

	template <class iter_t,  typename compare>
	void sample_sort (iter_t first, iter_t last, compare comp);

	template <class iter_t>
	void sample_sort (iter_t first, iter_t last, uint32_t num_thread);

	template <class iter_t,  typename compare>
	void sample_sort (iter_t first, iter_t last, compare comp, uint32_t num_thread);

[endsect] [/section 2.2.- Parallel ( parallel_sort, parallel_stable_sort, sample_sort)]

[section 2.3.- less_ptr_no_null]

Sometimes, we don't want sort physically the data by a concept. In such cases we can create a vector of pointers or iterators to the elements, named index, and sort the index. This permits keeping separate indexes into the the same data set at the same time, each sorted by different concepts.

To sort an index , we have a special comparison object less_ptr_no_null , which permits calls to the internal comparison between objects, from the pointers to the iterators. The less_ptr_no_null object receives in the constructor the comparison object between two objects. This comparison object make trivial the sorting of a index


	//---------------------------------------------------------------------------
	/// @class less_ptr_no_null
	///
	/// @remarks this is the comparison object for a pair of (non-null) pointers.
	//---------------------------------------------------------------------------
	template    <   class iter_t ,
                    class comp_t
                    = std::less <typename iterator_traits<iter_t>::value_type> >
	struct less_ptr_no_null
	{   //----------------------------- Variables -----------------------
		comp_t comp ;
		//----------------------------- Functions ----------------------
		inline less_ptr_no_null (comp_t C1 = comp_t()): comp (C1) {};
	   
		inline bool operator () (iter_t T1, iter_t T2) const
		{   return  comp (*T1 ,*T2);
		};
	};


In this example, there are structures sorted by the num field , but we create an index with the elements sorted by name, and another for to sorted by weight. It creates the less_ptr_no_null comparison objects, and sorts the indices, and then prints the results.


	#include <iostream>
	#include <vector>
	#include <iterator>
	#include <cassert>

	#include <boost/sort/parallel/sort.hpp>

	using namespace std;
	namespace bs_sort = boost::sort::parallel;
	using bs_sort::less_ptr_no_null;

	struct member
	{   uint32_t num;
		std::string name;
		float weight;
	};
	typedef typename vector<member>::iterator iter_t;

	struct cmp_num
	{   bool operator() ( const member &m1, const member &m2) const
		{   return (m1.num < m2.num); };
	};

	struct cmp_name
	{   bool operator() (const member &m1, const member &m2)const
		{   return (m1.name < m2.name); };
	};

	struct cmp_weight
	{   bool operator() (const member &m1, const member &m2) const
		{   return (m1.weight < m2.weight); };
	};

	ostream & operator << (ostream & out, const member &m)
	{   out<<m.num<<" - "<<m.name<<" - "<<m.weight<<endl;
		return out ;
	};

	int main (int, char*[])
	{   
		// The data are sorted by number
		vector<member> VM = { {1, "Peter", 85.6},   {2, "Hanna", 63.4},
		                      {3, "John",  83.6},   {4, "Elsa",  56.6} };
		
		vector<iter_t> Ix_name, Ix_weight;
		for (iter_t it= VM.begin(); it != VM.end(); ++it)
		{   Ix_name.push_back (it);
		    Ix_weight.push_back(it);
		};

		typedef less_ptr_no_null <iter_t, cmp_name>     compare_name ;
		typedef less_ptr_no_null <iter_t, cmp_weight>   compare_weight ;

		bs_sort::sort (Ix_name.begin(),   Ix_name.end(),   compare_name  ());
		bs_sort::sort (Ix_weight.begin(), Ix_weight.end(), compare_weight());

		cout<<"Printing sorted by number \n";
		for (auto it = VM.begin(); it != VM.end(); ++it) cout<<(*it);

		cout<<"Printing sorted by name \n";
		for (auto it = Ix_name.begin(); it != Ix_name.end(); ++it) cout<<(*(*it));

		cout<<"Printing sorted by weight \n";
		for (auto it = Ix_weight.begin(); it != Ix_weight.end(); ++it) cout<<(*(*it));

		return 0;
	};


The output of the program is


	Printing sorted by number
	1 - Peter - 85.6
	2 - Hanna - 63.4
	3 - John - 83.6
	4 - Elsa - 56.6
	Printing sorted by name
	4 - Elsa - 56.6
	2 - Hanna - 63.4
	3 - John - 83.6
	1 - Peter - 85.6
	Printing sorted by weight
	4 - Elsa - 56.6
	2 - Hanna - 63.4
	3 - John - 83.6
	1 - Peter - 85.6

[endsect] [/[section 2.3.- less_ptr_no_null] ]

[endsect] [/section 2.- Algorithms ]

[section 3.- Benchmarks ]

The goal of the benchmarks is to show a first approach to the performance of the algorithms. The performance can have many variations depending of the machine and their characteristics, as power of process, cache size, memory bandwidth, number of cores ....

There is other repository,([@https://github.com/fjtapia/sort_parallel_benchmark]) with all the code, instructions and scripts for to compile and execute the benchmarks. These repository don't belong to Boost, because contains non free code as TBB and Microsoft PPL, used for to compare the speed and memory used with the Boost Sort Parallel

Each algorithm have an "optimal" relation between the characteristics of the machine. By example, if you change to other machine with the same processor, cores, but with better memory bandwidth, some algorithms are more beneficiary than others.

The invariant characteristics of an algorithm are associated to their internal design, which  condition the memory usage, and their performance. By example,  the GCC parallel sort, with many cores, is faster than Threading Building Blocks (TBB), because have a better division of the work between the cores, but TBB use a half of the memory needed by GCC Parallel Sort.

In the processors with the Hyper Threading activate, Boost Parallel Sort usually is faster than GCC Parallel Sort. But In the Machines with the Hyper Threading not activate, GCC Parallel Sort is faster than Boost Parallel Sort.

[h3 Description]

The benchmark of these algorithms try to measure the speed in a wide range of cases, trying to provide useful information in all situations.
There are 3 benchmarks ;

# Sort of 100000000 uint64_t numbers randomly generated. The utility of this benchmark is to see the speed with small elements with a very fast comparison.

# Sort of 10000000 of strings randomly filled.  The comparison is no so easy as the integers.

# Sort of objects of several sizes. The objects are arrays of 64 bits numbers, randomly filled. We will check with arrays of 1 , 2 , 4,  8, 16, 32 and 64 numbers.

[table Objects
[[Definition of the object][Bytes][Number of elements to sort]]
[[uint64_t [1] ][8][100 000 000 ]]
[[uint64_t [2] ][16][50 000 000 ]]
[[uint64_t [4] ][32][25 000 000 ]]
[[uint64_t [8] ][64][12 500 000 ]]
[[uint64_t [16] ][128][6 250 000 ]]
[[uint64_t [32] ][256][3 125 000 ]]
[[uint64_t [64] ][512][1 562 500 ]]
]

	template <uint32_t NN>
	struct int_array
	{   uint64_t M[NN];
	};



The comparison between objects can be of two ways:

* Heavy comparison : The comparison is done with the sum of all the numbers of the array. In each comparison, make the sum.
* Light comparison : It's done using only the first number of the array, as a key in a register.



[section 3.1.- Linux 64 GCC 5.2 Benchmarks]

The benchmark are running in a  machine with a I7  5820 3.3 GHz 6 cores, 12 threads, quad channel memory (2133 MHz) with Ubuntu and the GCC 5.2 compiler


[section 3.1.1.- Single Thread Algorithms]

The algorithms involved in this benchmark are :

[table
[[Algorithm][Stable][Memory used][Comments]]
[[GCC sort][no][N + Log N 	]]
[[boost sort][no][N + Log N]]
[[GCC stable_sort][yes][N + N / 2]]
[[Boost stable_sort][yes][N + N / 2]]
[[Boost spreadsort][yes][N + Log N][Extremely fast algorithm, only for integers, floats and strings]]
]

[h4 Integer Benchmark Sort of 100000000 64 bits numbers, randomly filled]
 
[table
[[Algorithm][Time][Memory]]
[[GCC sort][8.33 secs][784 MB]]
[[Boost sort][8.11 secs][784 MB]]
[[GCC stable sort][8.69 secs][1176 MB]]
[[Boost stable sort][8.75 secs][1175 MB]]
[[Boost Spreadsort][4.33 secs][784 MB]]
]

[h4 Strings Benchmark Sort of 10 000 000 strings randomly filled]
 
[table
[[Algorithm][Time][Memory]]
[[GCC sort][6.39 secs][820 MB]]
[[Boost sort][7.01 secs][820 MB]]
[[GCC stable sort][12.99 secs][1132 MB]]
[[Boost stable sort][9.17 secs][976 MB]]
[[Boost Spreadsort][2.44 secs][820 MB]]
]

[h4 Objects  Benchmark]

Sorting of objects of different sizes. The objects are arrays of 64 bits numbers. This benchmark is done using two kinds of comparison.

[*Heavy comparison] : The comparison is done with the sum of all the numbers of the array. In each comparison, make the sum.

[table
[[Algorithm][8 bytes][16 bytes][32 bytes][64 bytes][128 bytes][256 bytes][512 bytes][Memory used]]
[[GCC sort][8.75][4.49][3.03][1.97][1.71][1.37][1.17][783 MB]]
[[Boost sort][8.19][4.42][2.65][1.91][1.67][1.35][1.09][783 MB]]
[[GCC stable_sort][10.23][5.67][3.67][2.94][2.6][2.49][2.34][1174 MB]]
[[Boost stable_sort][8.85][5.11][3.18][2.41][2.01][1.86][1.60][1174 MB]]
]


[*Light comparison] : It's done using only the first number of the array, as a key in a register.

[table
[[Algorithm][8 bytes][16 bytes][32 bytes][64 bytes][128 bytes][256 bytes][512 bytes][Memory used]]
[[GCC sort][8.69][4.31][2.35][1.50][1.23][0.86][0.79][783 MB]]
[[Boost sort][8.18][4.04][2.25][1.45][1.24][0.88][0.76][783 MB]]
[[GCC stable_sort][10.34][5.26][3.20][2.57][2.47][2.41][2.30][1174 MB]]
[[Boost stable_sort][8.92][4.59][2.51][1.94][1.68][1.68][1.50][1174 MB]]
]

[endsect][/section 3.1.1.- Single Thread Algorithms]

[section 3.1.2.- Parallel Algorithms]

The algorithms involved in this benchmark are :

[table
[[Algorithm][Stable][Memory used][Comments]]
[[GCC parallel sort][No][2N][Based on OpenMP]]
[[TBB parallel sort][No][N + LogN][]]
[[Boost parallel sort][No][N +block_size*num threads][New parallel algorithm]]
[[GCC parallel stable sort][Yes][2 N][Based on OpenMP]]
[[Boost parallel stable sort][Yes][N / 2][]]
[[Boost sample sort][Yes][N]] 	
[[TBB parallel stable sort][Yes][N][Experimental code, not in the TBB official]]
]

The block_size is an internal parameter of the algorithm, which  in order to achieve the highest speed, change according the size of the objects to sort according to the next table. The strings use a block_size of 128.

[table BlockSize
[[object size (bytes)]				[1 - 15][16 - 31][32 - 63][64 - 127][128 - 255][256 - 511][512 -]]
[[block_size (number of elements)]	[4096]	[2048]		[1024][768][512][256][128]]
]

For the benchmark I use the next additional code:

* Threading Building Blocks ( TBB)
* OpenMP
* Threading Building Block experimental code ( [@https://software.intel.com/sites/default/files/managed/48/9b/parallel_stable_sort.zip] )


The most significant of this parallel benchmark is the comparison between the Parallel Sort algorithms. GCC parallel sort is extremely fast with many cores, but need an auxiliary memory of the same size then the data. In the other side Threading Building Blocks (TBB), is not so fast with many cores , but the auxiliary memory is LogN.

The Boost Parallel Sort (internally named Block Indirect Sort), is a new algorithm created and implemented by the author for this library, which combine the speed of GCC Parallel sort, with a small memory consumption (block_size elements for each thread). The worst case for this algorithm is when have very big elements and many threads. With big elements (512 bytes), and 12 threads, The memory measured was:

# GCC Parallel Sort (OpenMP) 	   1565 MB
# Threading Building Blocks (TBB) 	783 MB
# Block Indirect Sort 	            812 MB

In machines with a small number of HW threads, TBB is faster than GCC, but with a great number of HW threads GCC is more faster than TBB. Boost Parallel Sort have similar speed than GCC  Parallel Sort with a great number of HW threads, and similar speed to TBB with a small number,  If you  are interested in a brief description of the algorithm, you can find here, and if you are interested in a detailed description of the algorithm, you can find here

[h4 Integer Benchmark Sort of 100 000 000 64 bits numbers, randomly filled]

[table
[[Algorithm][time (secs)][memory (MB)]]
[[OMP parallel_sort][1.25][1560]]
[[TBB parallel_sort][1.64][783]]
[[Boost parallel_sort][1.08][786]]
[[OMP parallel_stable_sort][1.56][1948]]
[[TBB parallel_stable_sort][1.56][1561]]
[[Boost sample_sort][1.19][1565]]
[[Boost parallel_stable_sort][1.54][1174]]
]

[h4 Strings Benchmark Sort of 10000000 strings randomly filled]

[table
[[Algorithm][time (secs)][memory (MB)]]
[[OMP parallel_sort][1.49][2040]]
[[TBB parallel_sort][1.84][820]]
[[Boost parallel_sort][1.30][822]]
[[OMP parallel_stable_sort][2.25][2040]]
[[TBB parallel_stable_sort][2.10][1131]]
[[Boost sample_sort][1.51][1134]]
[[Boost parallel_stable_sort][2.10][977]]
]

[h4 Objects Benchmark]

Sorting of objects of different sizes. The objects are arrays of 64 bits number. This benchmark is done using two kinds of comparison.


Heavy comparison : The comparison is done with the sum of all the numbers of the array. In each comparison, make the sum.

[table
[[Algorithm][8 bytes][16 bytes][32 bytes][64 bytes][128 bytes][256 bytes][512 bytes][Memory used]]
[[OMP parallel_sort][1.27][0.72][0.56][0.45][0.41][0.39][0.32][1565 MB]]
[[TBB parallel_sort][1.63][0.8][0.56][0.5][0.44][0.39][0.32][783 MB]]
[[Boost parallel_sort][1.13][0.67][0.53][0.47][0.43][0.41][0.34][812 MB]]
[[OMP parallel_stable_sort][1.62][1.38][1.23][1.19][1.09][1.07][0.97][1954 MB]]
[[TBB parallel_stable_sort][1.58][1.02][0.81][0.76][0.73][0.73][0.71][1566 MB]]
[[Boost sample_sort][1.15][0.79][0.63][0.62][0.62][0.61][0.6][1566 MB]]
[[Boost parallel_stable_sort][1.58][1.02][0.8][0.76][0.73][0.73][0.71][1175 MB]]
]

Light comparison : It's done using only the first number of the array, as a key in a register.

[table
[[Algorithm][8 bytes][16 bytes][32 bytes][64 bytes][128 bytes][256 bytes][512 bytes][Memory used]]
[[OMP parallel_sort][1.24][0.71][0.48][0.41][0.38][0.35][0.32][1565 MB]]
[[TBB parallel_sort][1.66][0.8][0.52][0.43][0.4][0.35][0.32][783 MB]]
[[Boost parallel_sort][1.11][0.65][0.49][0.43][0.41][0.37][0.34][812 MB]]
[[OMP parallel_stable_sort][1.55][1.36][1.23][1.18][1.09][1.07][0.97][1954 MB]]
[[TBB parallel_stable_sort][1.58][0.91][0.75][0.72][0.71][0.72][0.71][1566 MB]]
[[Boost parallel_stable_sort][1.16][0.74][0.63][0.62][0.61][0.61][0.6][1566 MB]]
[[Boost sample_sort][1.56][0.91][0.75][0.72][0.72][0.72][0.71][1175 MB]]
]

[endsect][/section 3.1.2.- Parallel Algorithms]
[endsect][/section 3.1.- Linux 64 GCC 5.2 Benchmarks]

[section 3.2.- Windows 10 Visual Studio 2015 64 bits Benchmarks]

The benchmark are running in a  virtual machine with Windows 10 and 10 threads over a I7  5820 3.3 GHz  with Visual Studio 2015 C++ compiler

[section 3.2.1 -Single Thread Algorithms]

The algorithms involved in this benchmark are :

[table
[[Algorithm][Stable][Memory used][Comments]]
[[std::sort][no][N + Log N]]
[[Boost sort][no][N + Log N]]
[[std::stable_sort][yes][N + N / 2 ]]
[[Boost stable_sort][yes][N + N / 2]]
[[Boost spreadsort][yes][N + Log N][Extremely fast algorithm, only for integers, floats and strings]]
]

[h4 Integer Benchmark Sort of 100000000 64 bits numbers, randomly filled]

[table
[[Algorithm][time (secs)][memory (MB)]]
[[std::sort][13][763 MB]]
[[Boost sort][10.74][763 MB]]
[[std::stable_sort][14.94][1144 MB]]
[[Boost stable_sort][13.37][1144 MB]]
[[Boost spreadsort][9.58][763 MB]]
]

[h4 Strings Benchmark Sort of 10 000 000 strings randomly filled]

[table
[[Algorithm][time (secs)][memory (MB)]]
[[std::sort][13.3][862 MB]]
[[Boost sort][13.6][862 MB]]
[[std::stable_sort][26.99][1015 MB]]
[[Boost stable_sort][20.64][1015 MB]]
[[Boost spreadsort][5.7][862 MB]]
]


[h4 Objects  Benchmark]

Sorting of objects of different sizes. The objects are arrays of 64 bits numbers. This benchmark is done using two kinds of comparison.

Heavy comparison : The comparison is done with the sum of all the numbers of the array. In each comparison, make the sum.

[table
[[Algorithm][8 bytes][16 bytes][32 bytes][64 bytes][128 bytes][256 bytes][512 bytes][Memory used]]
[[std::sort][13.36][6.98][4.2][2.58][2.87][2.37][2.29][763 MB]]
[[Boost sort][10.54][5.61][3.26][2.72][2.45][1.76][1.73][763 MB]]
[[std::stable_sort][15.49][8.47][5.47][3.97][3.85][3.55][2.99][1144 MB]]
[[Boost stable_sort][13.11][8.86][5.06][4.16][3.9][3.06][3.32][1144 MB]]
]

Light comparison : It's done using only the first number of the array, as a key in a register.

[table
[[Algorithm][8 bytes][16 bytes][32 bytes][64 bytes][128 bytes][256 bytes][512 bytes][Memory used]]
[[std::sort][14.15][7.26][4.33][2.69][1.92][1.98][1.73][763 MB]]
[[Boost sort][10.33][5][2.99][1.85][1.53][1.46][1.4][763 MB]]
[[std::stable_sort][14.68][7.64][4.29][3.33][3.22][2.86][3.08][1144 MB]]
[[Boost stable_sort][13.59][8.36][4.45][3.73][3.16][2.81][2.6][1144 MB]]
]
[endsect][/section 3.2.1 -Single Thread Algorithms]

[section 3.2.2.- Parallel Algorithms]

The algorithms involved in this benchmark are :

[table
[[Algorithm][Stable][Memory used][Comments]]
[[PPL  parallel sort][No][N]]
[[PPL parallel buffered sort][No][2 N]]
[[Boost parallel sort][No][N +block_size*num threads][New parallel algorithm]]
[[Boost parallel stable sort][Yes][N + N / 2]]
[[Boost sample sort][Yes][2 N]]
]
If you  are interested in a brief description of the new Boost parallel sort algorithm, you can find here, and if you are interested in a detailed description of the algorithm, you can find here

[h4 Integer Benchmark Sort of 100 000 000 64 bits numbers, randomly filled]

[table
[[Algorithm][time (secs)][memory (MB)]]
[[PPL parallel sort][3.11][764 ]]
[[PPL parallel buffered sort][1.74][1527]]
[[Boost parallel sort][2.1][764]]
[[Boost sample sort][2.78][1511]]
[[Boost parallel stable sort][3.3][1145]]
]

[h4 Strings Benchmark Sort of 10000000 strings randomly filled]

[table
[[Algorithm][time (secs)][memory (MB)]]
[[PPL parallel sort][3.76][864]]
[[PPL parallel buffered sort][3.77][1169]]
[[Boost parallel sort][3.41][866]]
[[Boost sample sort][3.74][1168]]
[[Boost parallel stable sort][5.7][1015]]
]

[h4 Objects Benchmark]

Sorting of objects of different sizes. The objects are arrays of 64 bits number. This benchmark is done using two kinds of comparison.

Heavy comparison : The comparison is done with the sum of all the numbers of the array. In each comparison, make the sum.

[table
[[Algorithm][8 bytes][16 bytes][32 bytes][64 bytes][128 bytes][256 bytes][512 bytes][Memory used]]
[[PPL parallel sort][2.84][1.71][1.01][0.84][0.89][0.77][0.65][764 MB]]
[[PPL parallel buffered sort][2.2][1.29][2][0.88][0.98][1.32][0.82][1527 MB]]
[[Boost parallel sort][1.93][0.82][0.9][0.72][0.77][0.68][0.69][764 MB]]
[[Boost sample sort][3.02][2.03][2.15][1.41][1.55][1.82][1.39][1526 MB]]
[[Boost parallel stable sort][3.36][2.67][1.62][1.45][1.38][1.19][1.37][1145 MB]]
]

Light comparison : It's done using only the first number of the array, as a key in a register.

[table
[[Algorithm][8 bytes][16 bytes][32 bytes][64 bytes][128 bytes][256 bytes][512 bytes][Memory used]]
[[PPL parallel sort][3.1][1.37][0.97][0.7][0.61][0.58][0.57][764 MB]]
[[PPL parallel buffered sort][2.31][1.39][0.9][0.88][1.1][0.89][1.44][1527 MB]]
[[Boost parallel sort][2.15][1.21][0.7][0.72][0.41][0.51][0.54][764 MB]]
[[Boost sample sort][3.4][1.94][1.56][1.41][2][1.41][1.96][1526 MB]]
[[Boost parallel stable sort][3.56][2.37][1.79][1.45][1.72][1.34][1.44][1145 MB]]
]

[endsect][/section 3.2.2.- Parallel Algorithms]
[endsect][/section 3.2.- Windows 10 Visual Studio 2015 64 bits Benchmarks]
[endsect][/section 3.- Benchmarks]
[br]
[section 4.- Bibliography]


[01] Introduction to Algorithms, 3rd Edition (Thomas H. Cormen, Charles E. Leiserson, Ronald L.
Rivest, Clifford Stein)
     
[02] C++ STL  Sort Algorithms

[03] Algorithm + Data Structures = Programs ( Nicklaus Wirth) Prentice Hall Series in Automatic Computation

[4]  Structured Parallel Programming: Patterns for Efficient Computation (Michael McCool, James Reinders, Arch Robison)

[endsect][/section 4.- Bibliography]

[section 5.- Gratitude]
To CESVIMA ([@http://www.cesvima.upm.es/]), Centro de Cálculo de la Universidad Politécnica de
Madrid. When need machines for to tune this algorithm, I contacted with the investigation department of
many Universities of Madrid. Only them, help me.
[br][br]
To Hartmut Kaiser, Adjunct Professor of Computer Science at Louisiana State University. By their faith in my work,
[br][br]
To Steven Ross, by their infinite patience in the long way in the develop of this algorithm, and their wise
advises.
[br][br]
[endsect][/section 5.- Gratitude]
  
[/
  Copyright (c) 2017 Francisco Tapia
  Distributed under the Boost Software License,
  Version 1.0. (See accompanying file LICENSE_1_0.txt
  or copy at http://boost.org/LICENSE_1_0.txt)
]

